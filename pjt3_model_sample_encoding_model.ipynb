{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TFMISY2x5nO7"
   },
   "outputs": [],
   "source": [
    "## 비디오 인코딩 모델 생성\n",
    "  ## 베이스 모델: InceptionV3\n",
    "  ## 데이터\n",
    "    # x_data: video files\n",
    "    # y_data: sentence_kwd\n",
    "\n",
    "  ## 모델 목표\n",
    "    # InceptionV3를 사용해 각 장면에서 추출한 특징을 sentence_kwd와 매칭해 해당 장면은 kwd 에 관련된다는 패턴 생성\n",
    "\n",
    "  ## 목표 추론 결과\n",
    "    # valid data 입력시, 해당 장면에 대한 올바른 키워드를 예측하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "O3B0t_0C6kRv"
   },
   "outputs": [],
   "source": [
    "# basic import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from google.colab import drive\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NeaosTFy6uQE",
    "outputId": "d9a3f9bc-944d-41e1-f092-0b3008908204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "unizipped files:  ['df_main.csv', 'D3_DA_0527_000042.mp4', 'D3_DA_0603_000001.mp4', 'D3_DA_0601_000001.csv', 'D3_DA_0603_000001.csv', 'D3_DA_0609_000001.csv', 'D3_DA_0601_000001.mp4', 'D3_DA_0610_000001.mp4', 'D3_DA_0609_000001.mp4', 'D3_DA_0610_000001.csv', 'D3_DA_0527_000042.csv']\n"
     ]
    }
   ],
   "source": [
    "# data load and unzip\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "zip_file_path = '/content/drive/My Drive/pjt_3_data/drive_upload_sample.zip'\n",
    "%mkdir 'pjt_3_sample'\n",
    "\n",
    "!cp \"{zip_file_path}\" \"/content/\"\n",
    "\n",
    "!unzip -q \"/content/drive_upload_sample.zip\" -d \"/content/pjt_3_sample/\"\n",
    "\n",
    "print('unizipped files: ', os.listdir('/content/pjt_3_sample'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "f18vaCPb9bId",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cOR8b-1y6xlx"
   },
   "outputs": [],
   "source": [
    "# preprocessing: video, txt data\n",
    "\n",
    "main_df = pd.read_csv('./try_first/df_main.csv', encoding='utf-8')\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "video_data = []\n",
    "context_data = []\n",
    "\n",
    "def convert_time_to_seconds(time_str):\n",
    "  if isinstance(time_str, float):\n",
    "    return time_str\n",
    "\n",
    "  minutes, seconds = time_str.split(':')\n",
    "  return int(minutes) * 60 + float(seconds)\n",
    "\n",
    "def load_video_frames(video_path, time_start, time_end, max_frames=60, resize=(299,299)):\n",
    "  cap = cv2.VideoCapture(video_path)\n",
    "  frames = []\n",
    "  frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "  frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "  start_frame = int(convert_time_to_seconds(time_start) * frame_rate)\n",
    "  end_frame = int(min(convert_time_to_seconds(time_end) * frame_rate, frame_count))\n",
    "\n",
    "  current_frame = 0\n",
    "  while current_frame < start_frame:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "      break\n",
    "    current_frame += 1\n",
    "\n",
    "  while current_frame < end_frame and len(frames) < max_frames:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "      break\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, resize)\n",
    "    frame = preprocess_input(frame)\n",
    "    frames.append(frame)\n",
    "    current_frame += 1\n",
    "\n",
    "  while len(frames) < max_frames:\n",
    "    black_frame = np.zeros((resize[0], resize[1], 3), np.uint8)\n",
    "    frames.append(black_frame)\n",
    "\n",
    "  cap.release()\n",
    "  return np.array(frames)\n",
    "\n",
    "def load_and_process_video_and_text(main_df, folder_path):\n",
    "  for label_file_id in main_df['id']:\n",
    "    label_file_path = os.path.join(folder_path, label_file_id + '.csv')\n",
    "    labels_df = pd.read_csv(label_file_path, encoding='utf-8')\n",
    "\n",
    "    for _, row in labels_df.iterrows():\n",
    "      video_path = os.path.join(folder_path, row['video_name'])\n",
    "      time_start, time_end = row['time_start'], row['time_end']\n",
    "      keywords =  row['sentence_kwd']\n",
    "      keywords_str = ' '.join(keywords)\n",
    "\n",
    "      video_frames = load_video_frames(video_path, time_start, time_end)\n",
    "      video_data.append(video_frames)\n",
    "\n",
    "      context_data.append(keywords_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "nS3RKrhF63sc",
    "outputId": "7b9ebeb0-87e0-4bd9-867a-eb8b95733555",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (24,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m x_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(x_train)\n\u001b[0;32m     15\u001b[0m x_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(x_test)\n\u001b[1;32m---> 16\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_test)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (24,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# train, test split\n",
    "\n",
    "folder_path = './try_first'\n",
    "load_and_process_video_and_text(main_df, folder_path)\n",
    "\n",
    "tokenizer.fit_on_texts(context_data)\n",
    "context_sequences = tokenizer.texts_to_sequences(context_data)\n",
    "\n",
    "x = video_data\n",
    "y = context_sequences\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 9, 5, 7, 2, 4, 1, 1, 15, 10, 16, 8, 14, 3, 8, 1, 1, 6, 3, 3, 6, 14, 1],\n",
       " [1, 9, 5, 7, 2, 4, 1, 1, 6, 2, 11, 13, 12, 4, 17, 1],\n",
       " [1,\n",
       "  9,\n",
       "  5,\n",
       "  7,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  9,\n",
       "  2,\n",
       "  11,\n",
       "  13,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  21,\n",
       "  10,\n",
       "  5,\n",
       "  4,\n",
       "  6,\n",
       "  1,\n",
       "  1,\n",
       "  10,\n",
       "  3,\n",
       "  21,\n",
       "  10,\n",
       "  12,\n",
       "  17,\n",
       "  3,\n",
       "  10,\n",
       "  2,\n",
       "  6,\n",
       "  5,\n",
       "  10,\n",
       "  1],\n",
       " [1,\n",
       "  9,\n",
       "  5,\n",
       "  7,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  17,\n",
       "  5,\n",
       "  3,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  8,\n",
       "  3,\n",
       "  2,\n",
       "  6,\n",
       "  1,\n",
       "  1,\n",
       "  6,\n",
       "  16,\n",
       "  7,\n",
       "  15,\n",
       "  11,\n",
       "  3,\n",
       "  10,\n",
       "  1,\n",
       "  1,\n",
       "  9,\n",
       "  2,\n",
       "  6,\n",
       "  3,\n",
       "  10,\n",
       "  1],\n",
       " [1, 9, 5, 7, 2, 4, 1, 1, 11, 5, 5, 13, 8, 1, 1, 18, 14, 5, 4, 3, 1],\n",
       " [1, 9, 5, 7, 2, 4, 1, 1, 8, 12, 6, 8, 1, 1, 18, 11, 2, 19, 3, 1],\n",
       " [1,\n",
       "  9,\n",
       "  5,\n",
       "  7,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  6,\n",
       "  2,\n",
       "  11,\n",
       "  13,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  18,\n",
       "  14,\n",
       "  5,\n",
       "  4,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  6,\n",
       "  2,\n",
       "  11,\n",
       "  13,\n",
       "  8,\n",
       "  1],\n",
       " [1, 9, 5, 7, 2, 4, 1, 1, 20, 10, 12, 4, 13, 8, 1, 1, 9, 2, 6, 3, 10, 1],\n",
       " [1, 9, 5, 7, 2, 4, 1, 1, 15, 10, 16, 8, 14, 3, 8, 1, 1, 6, 3, 3, 6, 14, 1],\n",
       " [1,\n",
       "  9,\n",
       "  5,\n",
       "  7,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  10,\n",
       "  3,\n",
       "  7,\n",
       "  5,\n",
       "  23,\n",
       "  3,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  9,\n",
       "  2,\n",
       "  6,\n",
       "  3,\n",
       "  10,\n",
       "  1,\n",
       "  1,\n",
       "  10,\n",
       "  3,\n",
       "  21,\n",
       "  10,\n",
       "  12,\n",
       "  17,\n",
       "  3,\n",
       "  10,\n",
       "  2,\n",
       "  6,\n",
       "  5,\n",
       "  10,\n",
       "  1],\n",
       " [1,\n",
       "  9,\n",
       "  5,\n",
       "  7,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  18,\n",
       "  5,\n",
       "  16,\n",
       "  10,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  9,\n",
       "  2,\n",
       "  6,\n",
       "  3,\n",
       "  10,\n",
       "  1,\n",
       "  1,\n",
       "  6,\n",
       "  16,\n",
       "  7,\n",
       "  15,\n",
       "  11,\n",
       "  3,\n",
       "  10,\n",
       "  1],\n",
       " [1, 7, 2, 4, 1, 1, 7, 5, 23, 12, 4, 17, 1],\n",
       " [1,\n",
       "  9,\n",
       "  5,\n",
       "  7,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  19,\n",
       "  11,\n",
       "  5,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  6,\n",
       "  16,\n",
       "  7,\n",
       "  15,\n",
       "  11,\n",
       "  3,\n",
       "  10,\n",
       "  1,\n",
       "  1,\n",
       "  11,\n",
       "  12,\n",
       "  20,\n",
       "  1],\n",
       " [1, 9, 5, 7, 2, 4, 1, 1, 18, 10, 3, 18, 2, 10, 3, 8, 1, 1, 9, 2, 8, 14, 1],\n",
       " [1,\n",
       "  7,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  22,\n",
       "  2,\n",
       "  7,\n",
       "  12,\n",
       "  4,\n",
       "  3,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  9,\n",
       "  2,\n",
       "  6,\n",
       "  3,\n",
       "  10,\n",
       "  1,\n",
       "  1,\n",
       "  15,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  11,\n",
       "  3,\n",
       "  1],\n",
       " [1, 9, 5, 7, 2, 4, 1, 1, 11, 12, 3, 8, 1, 1, 19, 14, 2, 12, 10, 1],\n",
       " [1,\n",
       "  7,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  22,\n",
       "  2,\n",
       "  7,\n",
       "  12,\n",
       "  4,\n",
       "  3,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  9,\n",
       "  2,\n",
       "  6,\n",
       "  3,\n",
       "  10,\n",
       "  1,\n",
       "  1,\n",
       "  15,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  11,\n",
       "  3,\n",
       "  1],\n",
       " [1,\n",
       "  9,\n",
       "  5,\n",
       "  7,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  14,\n",
       "  5,\n",
       "  11,\n",
       "  20,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  20,\n",
       "  16,\n",
       "  7,\n",
       "  15,\n",
       "  15,\n",
       "  3,\n",
       "  11,\n",
       "  11,\n",
       "  8,\n",
       "  1],\n",
       " [1, 9, 5, 7, 2, 4, 1, 1, 8, 12, 6, 8, 1, 1, 21, 3, 4, 19, 3, 1],\n",
       " [1, 9, 5, 7, 2, 4, 1, 1, 6, 2, 11, 13, 12, 4, 17, 1],\n",
       " [1, 9, 5, 7, 2, 4, 1, 1, 13, 4, 5, 19, 13, 8, 1, 1, 15, 5, 6, 6, 11, 3, 1],\n",
       " [1,\n",
       "  7,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  22,\n",
       "  2,\n",
       "  7,\n",
       "  12,\n",
       "  4,\n",
       "  3,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  9,\n",
       "  2,\n",
       "  6,\n",
       "  3,\n",
       "  10,\n",
       "  1,\n",
       "  1,\n",
       "  15,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  11,\n",
       "  3,\n",
       "  1],\n",
       " [1, 9, 5, 7, 2, 4, 1, 1, 11, 5, 5, 13, 8, 1, 1, 18, 14, 5, 4, 3, 1],\n",
       " [1, 9, 5, 7, 2, 4, 1, 1, 8, 3, 3, 8, 1, 1, 19, 5, 7, 18, 16, 6, 3, 10, 1]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xCbOKg7yPYb8",
    "outputId": "31407787-ace5-4451-9d81-6bc9670b9141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 60, 299, 299, 3)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## train, test set check\u001b[39;00m\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;66;03m# x_train, x_test는 비디오 데이터이므로 (샘플수, 프레임수, 높이, 너비, 차원수)로 나와야 함\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_test\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "## train, test set check\n",
    "  # x_train, x_test는 비디오 데이터이므로 (샘플수, 프레임수, 높이, 너비, 차원수)로 나와야 함\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbXCtxkKVwqt",
    "outputId": "6885b490-1065-4086-f311-320d1888a3bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 299, 299, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OHUSt0Y6WlA3",
    "outputId": "ae31a9da-6947-46db-ebe7-7fbe155bfe25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video 0: shape = (120, 299, 299, 3)\n",
      "video 1: shape = (120, 299, 299, 3)\n",
      "video 2: shape = (120, 299, 299, 3)\n",
      "video 3: shape = (120, 299, 299, 3)\n",
      "video 4: shape = (120, 299, 299, 3)\n",
      "video 5: shape = (120, 299, 299, 3)\n",
      "video 6: shape = (120, 299, 299, 3)\n",
      "video 7: shape = (120, 299, 299, 3)\n",
      "video 8: shape = (120, 299, 299, 3)\n",
      "video 9: shape = (120, 299, 299, 3)\n",
      "video 10: shape = (120, 299, 299, 3)\n",
      "video 11: shape = (90, 299, 299, 3)\n",
      "video 12: shape = (120, 299, 299, 3)\n",
      "video 13: shape = (120, 299, 299, 3)\n",
      "video 14: shape = (120, 299, 299, 3)\n",
      "video 15: shape = (120, 299, 299, 3)\n",
      "video 16: shape = (120, 299, 299, 3)\n",
      "video 17: shape = (120, 299, 299, 3)\n",
      "video 18: shape = (120, 299, 299, 3)\n",
      "video 19: shape = (120, 299, 299, 3)\n",
      "video 20: shape = (120, 299, 299, 3)\n",
      "video 21: shape = (120, 299, 299, 3)\n",
      "video 22: shape = (120, 299, 299, 3)\n",
      "video 23: shape = (120, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "## x_train or x_test 데이터의 크기가 올바르지 않을 때 각 비디오 데이터의 크기 확인 코드\n",
    " ## 데이터 크기가 올바르지 않을 경우: 추출된 프레임 수가 불일치해서 np.array로 변환되지 못했기 때문\n",
    "  ## 추출되는 프레임 수가 다른 이유: 타임스탬프의 길이 차이\n",
    "    ## 예시: 초당프레임: 30, 최대 추출 프레임수: 120, 스탬프1: 5초, 스탬프2: 3초\n",
    "      # 스탬프 1은 총 150프레임을 구성되므로(5*30) 150중 120프레임 추출됨\n",
    "      # 스탬프 2는 총 90프레임으로 구성되므로(3*30) 90중 90프레임이 추출됨\n",
    "\n",
    "    ## 결론: 최대 프레임을 기준으로 패딩하거나, 타임스탬프 길이를 동일하게 정규화해야 함\n",
    "\n",
    "for i, video in enumerate(x_train):\n",
    "  print(f\"video {i}: shape = {video.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "otxnH8C963uh"
   },
   "outputs": [],
   "source": [
    "# model define\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding\n",
    "from tensorflow.keras.layers import Dropout, TimeDistributed\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False,\\\n",
    "                         pooling='avg')\n",
    "\n",
    "input_shape = (None, 299, 299, 3)\n",
    "video_input = Input(shape=input_shape)\n",
    "encoded_frames = TimeDistributed(base_model)(video_input)\n",
    "\n",
    "video_lstm = LSTM(256)(encoded_frames)\n",
    "video_dense = Dense(126, activation='relu')(video_lstm)\n",
    "\n",
    "num_keywords = 10\n",
    "embedding_dim = 100\n",
    "max_num_keywords = 1000\n",
    "keyword_input = Input(shape=(None,), dtype='int32')\n",
    "keyword_embedding = Embedding(max_num_keywords, embedding_dim)(keyword_input)\n",
    "keyword_lstm = LSTM(126)(keyword_embedding)\n",
    "\n",
    "keyword_dense = Dense(64, activation='relu')(keyword_lstm)\n",
    "\n",
    "combined = Concatenate()([video_dense, keyword_dense])\n",
    "predictions = Dense(units=num_keywords, activation='softmax')(combined)\n",
    "\n",
    "model = Model(inputs=[video_input, keyword_input], outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_pCM4_r963zk",
    "outputId": "4aae9f61-0c48-4b59-b25a-8ac390b2fe52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, None, 299, 299, 3)   0         []                            \n",
      "                             ]                                                                    \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDi  (None, None, 2048)           2180278   ['input_5[0][0]']             \n",
      " stributed)                                               4                                       \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 100)            100000    ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               (None, 256)                  2360320   ['time_distributed_1[0][0]']  \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               (None, 126)                  114408    ['embedding_1[0][0]']         \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 126)                  32382     ['lstm_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 64)                   8128      ['lstm_3[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 190)                  0         ['dense_2[0][0]',             \n",
      " )                                                                   'dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 10)                   1910      ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24419932 (93.15 MB)\n",
      "Trainable params: 24385500 (93.02 MB)\n",
      "Non-trainable params: 34432 (134.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model compile\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZW3Cpo_ebim"
   },
   "outputs": [],
   "source": [
    "## 12월 21일 저녁 과제\n",
    "  ## 전처리 함수 재검토(일단 프레임 패딩 추가함)\n",
    "  ## 전처리 데이터 재생성\n",
    "  ## 모델 학습\n",
    "  ## 모델 결과 확인 및 데이터 증강(5개 -> 최대 100개까지)\n",
    "  ## 위의 작업을 반드시 집 데스크탑으로 실행해볼 것!!(눕지마!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ETlzD3L2632M"
   },
   "outputs": [],
   "source": [
    "# model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8ixkx-s634s"
   },
   "outputs": [],
   "source": [
    "# model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFPspYBL637U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDQ_T3sd639j"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
